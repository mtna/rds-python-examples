{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With the RDS Library\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RDS provides you with a powerful tool to access and manage data. Our API can quickly and efficiently filter the data and perform computations on it on the fly. It can also retrieve important metadata on each aspect of the data for you to perform more detailed analysis. To run this notebook, packages needed for generating the charts must be installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By utilizing a **Select** query, we are able to get the specific records of data we are interested in, along with performing standard computations, grouping, and ordering of that data at the same time. In the initial example below, we are interested in data revolving around COVID-19 deaths in Ohio, so we first create a connection to that data set through the `DataProduct` (To view other dataset, browse our catalog). With this data, we want to create a simple line plot of the number of deaths for the first 2 weeks of March. We specify the columns of data we want as the date of occurrence and as a computation that sums the deaths. Grouping by date ensures that we only have one record per date with the sum of deaths for that date. We then proceed to order the records and filter them to get the month and the amount of records we wanted.\n",
    "\n",
    "If we are interested in more extensive information around any of the columns, we could check the metadata contained within the results returned by the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rds import DataProduct\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "#Connect to the Ohio data set\n",
    "dp = DataProduct('https://covid19.richdataservices.com', 'us_oh', 'oh_doh_cases')\n",
    "#Query for the number of deaths over the first 2 weeks of March\n",
    "results = dp.select(cols=['date_stamp', 'deaths:sum(cnt_death)'], groupby=['date_stamp'], orderby=['date_stamp'], where=['date_stamp>=2020-03-01'], limit=14)\n",
    "\n",
    "#Plug in the data and build our line plot\n",
    "df = pd.DataFrame(results.records, columns = results.columns)\n",
    "sns.set(rc={'figure.figsize':(30, 10)})\n",
    "sns.lineplot(data=df, x=df.columns[0], y=df.columns[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizing the various options available through RDS, you can specify the data returned to be exactly what you need.\n",
    "\n",
    "In this next example, we are now making use of a **Tabulate** query with multiple dimensions so that we can see the amount of deaths for each county. If you think about a tabulation table, the **'dims'** would be the rows and columns and the **'measure'** would be the value to fill in each cell. We then proceed with filtering and ordering the data returned like before. Setting the parameter `inject=True` fills in any coded values with their labels. Variables with classifications that specify these codes can be found in the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rds import DataProduct\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "#Connect to the Ohio data set\n",
    "dp = DataProduct('https://covid19.richdataservices.com', 'us_oh', 'oh_doh_cases')\n",
    "#Query for the number of deaths for every county in Ohio\n",
    "results = dp.tabulate(dims=['us_county_fips'], measure=['Deaths:sum(cnt_death)'], orderby=['us_county_fips'])\n",
    "df = pd.DataFrame(results.records, columns = results.columns)\n",
    "\n",
    "#Getting the structure of the map\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "\n",
    "#Plug in the data and build our choropleth map\n",
    "fig = px.choropleth(df, geojson=counties, locations=df.columns[0], color='Deaths', color_continuous_scale=\"Reds\", range_color=(0, 100), scope=\"usa\", labels={'Deaths'})\n",
    "fig.update_geos(fitbounds=\"locations\")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}, width=1000, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without RDS\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting and organizing the data into a form you can work with is generally tedious and complicated. Below we demonstrate what you would need to do to get a single data set and format that data to be able to create the choropleth map you saw above.\n",
    "\n",
    "The first thing we have to do is get the data and filter it for exactly what we want. Let'ss see what our dataframe looks like after we do just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "#Get the data\n",
    "data = pd.read_csv('https://coronavirus.ohio.gov/static/COVIDSummaryData.csv')\n",
    "df = pd.DataFrame(data)\n",
    "#Filter the data\n",
    "df = df[['County','Death Count']]\n",
    "df = df.groupby(['County']).sum().reset_index()\n",
    "df = df.sort_values('County')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that doesn't look right. Seems that we understandably assumed the \"Death Counts\" would be and integer, but we actually have to transform it into integers ourselves. Let's try that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "#Get the data\n",
    "data = pd.read_csv('https://coronavirus.ohio.gov/static/COVIDSummaryData.csv')\n",
    "df = pd.DataFrame(data)\n",
    "#Filter the data\n",
    "df = df[['County','Death Count']]\n",
    "#Transform the data\n",
    "df['Death Count'] = df['Death Count'].astype(int)\n",
    "df = df.groupby(['County']).sum().reset_index()\n",
    "df = df.sort_values('County')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that not all values in the \"Death Counts\" column are in in a valid integer format! It turns out to be the \"Grand Total\" row, which isn't even wanted for our choropleth map so we can just drop it from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "#Get the data\n",
    "data = pd.read_csv('https://coronavirus.ohio.gov/static/COVIDSummaryData.csv')\n",
    "df = pd.DataFrame(data)\n",
    "#Filter the data\n",
    "df = df[['County','Death Count']]\n",
    "#Clean the data\n",
    "df = df[df['County'] != 'Grand Total']\n",
    "#Transform the data\n",
    "df['Death Count'] = df['Death Count'].astype(int)\n",
    "df = df.groupby(['County']).sum().reset_index()\n",
    "df = df.sort_values('County')\n",
    "print(df)\n",
    "\n",
    "#Getting the structure of the map\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "\n",
    "#Plug in the data and build our choropleth map\n",
    "fig = px.choropleth(df, geojson=counties, locations=df.columns[0], color='Death Count', color_continuous_scale=\"Reds\", range_color=(0, 100), scope=\"usa\", labels={'Deaths'})\n",
    "fig.update_geos(fitbounds=\"locations\")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}, width=1000, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataframe looks good now, so why isn't our choropleth map working with it?\n",
    "\n",
    "Unfortunately, the choropleth map requires the FIPS codes for each county where we only have the names. To get this work, we will have to convert each county name into its FIPS code and try again. If we were to just use RDS, we could switch from name to FIPS by setting `inject=True` in our query. That would've been so much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Get the data\n",
    "data = pd.read_csv('https://coronavirus.ohio.gov/static/COVIDSummaryData.csv')\n",
    "df = pd.DataFrame(data)\n",
    "#Filter the data\n",
    "df = df[['County','Death Count']]\n",
    "#Clean the data\n",
    "df = df[df['County'] != 'Grand Total']\n",
    "#Transform the data\n",
    "df['Death Count'] = df['Death Count'].astype(int)\n",
    "df = df.groupby(['County']).sum().reset_index()\n",
    "df = df.sort_values('County')\n",
    "\n",
    "#Scrape for the county FIPS codes\n",
    "html = requests.get(\"https://en.wikipedia.org/wiki/List_of_United_States_FIPS_codes_by_county\").text\n",
    "soup = BeautifulSoup(html,\"lxml\")\n",
    "table = soup.find('table', {\"class\":\"wikitable sortable\"}).find('tbody')\n",
    "\n",
    "#Replace the county names with their FIPS code\n",
    "state = ''\n",
    "for df_row in df.iterrows():\n",
    "    county = df_row[1]['County']\n",
    "    for tb_row in table.find_all('tr'):\n",
    "        cells = tb_row.findChildren('td')\n",
    "        if len(cells) == 3:\n",
    "            state = str(cells[2].text).strip()\n",
    "        \n",
    "        if len(cells) >= 2 and county in cells[1].text and state == 'Ohio':\n",
    "            df = df.replace(county, str(cells[0].text).strip())\n",
    "            break\n",
    "\n",
    "#Getting the structure of the map\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "\n",
    "#Plug in the data and build our choropleth map\n",
    "fig = px.choropleth(df, geojson=counties, locations=df.columns[0], color='Death Count', color_continuous_scale=\"Reds\", range_color=(0, 100), scope=\"usa\", labels={'Deaths'})\n",
    "fig.update_geos(fitbounds=\"locations\")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}, width=1000, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data from our CSV is missing the FIPS codes, we have to scrape them from wikipedia. Even after that, we still need to replace every single county name with its FIPS code in our dataframe before it'll work. The result of this is some ugly loops as well as slow code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, RDS handles all of the hard work of organizing, transforming, and cleaning the data, allowing you to focus on the presentation of the data instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See our [Catalog](./covid_19_catalog.ipynb) for a list of available data sets, as well as the metadata on any variables and their classifications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
